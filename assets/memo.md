# Fine-Tuning

## å‚è€ƒ

- [bedrock-fine-tuning/claude-haiku/01_Claude_Haiku_Fine_Tuning.ipynb](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/bedrock-fine-tuning/claude-haiku/01_Claude_Haiku_Fine_Tuning.ipynb)
- [Amazon Bedrock ã§ Anthropic ã® Claude 3 Haiku ã‚’å¾®èª¿æ•´ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã¨å“è³ªã‚’å‘ä¸Š](https://aws.amazon.com/jp/blogs/machine-learning/fine-tune-anthropics-claude-3-haiku-in-amazon-bedrock-to-boost-model-accuracy-and-quality/)
- [Amazon Kendra ã¨ Amazon Bedrock ã§æ§‹æˆã—ãŸ RAG ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã™ã‚‹ Advanced RAG æ‰‹æ³•ã®ç²¾åº¦å¯„ä¸æ¤œè¨¼](https://aws.amazon.com/jp/blogs/news/verifying-the-accuracy-contribution-of-advanced-rag-methods-on-rag-systems-built-with-amazon-kendra-and-amazon-bedrock/)
- [API ã¨ OSS ã€è“„ç©ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ç²¾åº¦ã‚’æ”¹å–„ã™ã‚‹ãªã‚‰ã©ã¡ã‚‰ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã™ã¹ãã‹ : è³ªå•å›ç­”ç·¨](https://aws.amazon.com/jp/blogs/news/cost-efficiency-of-api-and-oss-generative-ai/)
- [æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« OpenCALM ã®çŸ¥è­˜ã§ã‚¯ã‚¤ã‚ºç‹ã«æŒ‘æˆ¦ã™ã‚‹](https://aws.amazon.com/jp/blogs/news/open-calm-and-openai-chatgpt-accuracy-on-jaqket-experiment-in-amazon-sagemaker/)
- [Amazon Bedrock ã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚«ã‚¹ã‚¿ãƒ ã—ã¦å‰å¤§ãªãƒŸãƒ¥ãƒ¼ã‚¸ã‚·ãƒ£ãƒ³ã‚’é™è‡¨ã•ã›ãŸ(?)è©±](https://qiita.com/triwave33/items/b36f85f95db44d252e32)
- [Anthropic Tokenizer](https://lunary.ai/anthropic-tokenizer)
- [Fine-TuningğŸ˜ vs. RAGğŸ† (2024 Microsoft è«–æ–‡)](https://qiita.com/DeepMata/items/05221c2914d1cfbf32ee)
- [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° vs ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° vs RAG](https://myscale.com/blog/ja/prompt-engineering-vs-finetuning-vs-rag/)
- [Few-shot prompt engineering and fine-tuning for LLMs in Amazon Bedrock](https://aws.amazon.com/jp/blogs/machine-learning/few-shot-prompt-engineering-and-fine-tuning-for-llms-in-amazon-bedrock/)
- [ã™ã”ã„ã Langfuseï¼ãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨ˆç®—æ©Ÿèƒ½ã¨è©•ä¾¡æ©Ÿèƒ½ã‚’æ¤œè¨¼](https://qiita.com/moritalous/items/e07448ec0ec5e0132276)

## TODO

- [x] ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¿æŸ»
- [x] ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
- [x] Fine-Tuning Job ã®å®Ÿè¡Œ
  - model name: claude-3-haiku-ft-model
  - job name: claude-3-haiku-ft-job
  - role: claude-3-haiku-ft-role
- [x] è©•ä¾¡ã—ã¦ã¿ãŸã„
- [ ] æ¤œè¨¼çµæœãƒ–ãƒ­ã‚°ã®åŸ·ç­†
  - [x] create_val_dataset.py ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°

## Survey (fine-tuning ã®æ¤œè¨¼)

- èªå°¾ãŒã€Œã”ã–ã‚‹ã€
  - https://huggingface.co/datasets/bbz662bbz/databricks-dolly-15k-ja-gozaru?row=99
  - https://qiita.com/jovyan/items/c727392d6d6030433f84
- Amazon Bedrock ã® QA
  - https://aws.amazon.com/jp/blogs/machine-learning/improve-rag-accuracy-with-fine-tuned-embedding-models-on-amazon-sagemaker/
  - https://github.com/aws-samples/fine-tune-embedding-models-on-sagemaker/blob/main/sentence-transformer/multiple-negatives-ranking-loss/training.json
    - ã§ã‚‚ã“ã‚Œ 85 ä»¶ã—ã‹ãªã„ã€‚
- NVIDIA ã®ãƒ–ãƒ­ã‚°
  - https://resources.nvidia.com/ja-jp-llm-developer-day/how-to-use-peft-on-nemo-framework?ncid=no-ncid

## Memo

å¾®èª¿æ•´ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã‚ˆã‚Šã‚‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã®æ–¹ãŒé‡è¦ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ã«ã¯ã€å°è¦æ¨¡ãªãŒã‚‰ã‚‚é«˜å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (50 ï½ 100 è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å§‹ã‚ã‚‹ã®ãŒå¦¥å½“ã§ã™) ã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚è©•ä¾¡çµæœã«åŸºã¥ã„ã¦ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã‚’åå¾©ã—ã¦æ”¹è‰¯ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€èˆ¬ã«ã€é«˜å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ã€å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚ˆã‚Šå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒæœŸå¾…ã§ãã¾ã™ã€‚ãŸã ã—ã€ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã«é‡ç‚¹ã‚’ç½®ãã“ã¨ãŒé‡è¦ã§ã™ã€‚å¤§è¦æ¨¡ã§ã‚‚å“è³ªã®ä½ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœŸå¾…ã©ãŠã‚Šã«å‘ä¸Šã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã§ã™ã€‚

## Strategy

- ã¾ãšã¯ã€85-15 ä»¶ã§ split ã—ã¦ã€å­¦ç¿’ã•ã›ã¦ã¿ã‚‹ã‹ã€‚

  - 15 ä»¶åˆ†ã® validation dataset ã¯ã€è‡ªä½œã™ã‚‹ã‹ã€ã€
  - tool use ã®åˆ©ç”¨

- æ™®é€šã« 1 æ™‚é–“ã®è©¦è¡Œã§ 2 ä¸‡å††ã‹ã‹ã‚‹ã®ã§ã€æ…é‡ã«è¡Œã„ãŸã„ã€‚
- æƒ³å®šã‚·ãƒŠãƒªã‚ªã¨ã—ã¦ã¯ä»¥ä¸‹ã€‚
  - ãã¡ã‚“ã¨ FT ã§ãã¦ã„ã‚‹
  - FT ã®åŠ¹æœãŒè¦‹ã‚‰ã‚Œãªã„ã€‚
- ä¸Šè¨˜ã®åŠ¹æœã‚’è¦‹æ¥µã‚ã‚‰ã‚Œã‚‹è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ãªã„ã¨ã„ã‘ãªã„ã€‚

### ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®å‚è€ƒ

No commitment ã§ 50 åˆ†ã§æ¤œè¨¼ã‚’è¡Œã†ã“ã¨ï¼

- https://qiita.com/minorun365/items/4c5f69e120898179347d
- https://dev.classmethod.jp/articles/bedrock-pt-min-unit/

## References

- https://github.com/aws-samples/aws-ml-jp/pull/66
- https://aws.amazon.com/jp/blogs/news/cost-efficiency-of-api-and-oss-generative-ai/
- https://www.perplexity.ai/search/llmnofine-tuningwoxing-uji-nil-LXDILLZ.Q4ukZ9pY66Tnpg
- https://www.perplexity.ai/search/llmwofine-tuningsurukotote-jin-h8DcckwlSg6e_1ZoY.2SVA

### PFN ã® LLM ã® LoRA ã®ãƒ–ãƒ­ã‚°

- https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/

> ã“ã“ã§ã€æœ¬æ¥ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã¯åŒ»ç™‚ã‚„æ³•å¾‹ã¨ã„ã£ãŸç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«é–¢ã™ã‚‹çŸ¥è­˜ã®ã“ã¨ã§ã™ãŒã€å®Ÿé¨“è¨­å®šã‚’è€ƒæ…®ã—ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ãªã„ã§ã‚ã‚ã†æ—¥æœ¬èªã«ãŠã‘ã‚‹çŸ¥è­˜ã‚’æŒ‡ã™ã“ã¨ã¨ã—ã¾ã™ã€‚

- ãã®ä»–
  - https://www.ariseanalytics.com/activities/report/20240419-2/

### AWS Blog(Claude3 fine-tuning)

- [whats-news](https://aws.amazon.com/jp/about-aws/whats-new/2024/07/fine-tuning-anthropics-claude-3-haiku-bedrock-preview/)
- [Fine-tune Anthropicâ€™s Claude 3 Haiku in Amazon Bedrock to boost model accuracy and quality](https://aws.amazon.com/jp/blogs/machine-learning/fine-tune-anthropics-claude-3-haiku-in-amazon-bedrock-to-boost-model-accuracy-and-quality/)
- [ãƒ¢ãƒ‡ãƒ«ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹åœ°åŸŸã¨ãƒ¢ãƒ‡ãƒ«](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-model-supported.html)
- https://aws.amazon.com/jp/blogs/machine-learning/few-shot-prompt-engineering-and-fine-tuning-for-llms-in-amazon-bedrock/

### è©•ä¾¡ã®éƒ¨åˆ†

- https://qiita.com/moritalous/items/e07448ec0ec5e0132276

### qiita

- https://qiita.com/revsystem/items/303487a39eea5924187c
- https://qiita.com/moritalous/items/8d8e6b91c7289692644a
- https://qiita.com/moritalous/items/ff2763bcd9408a1b395a
- https://qiita.com/ren8k/items/3d5f66df251703b8407e
- https://qiita.com/kazuneet/items/9b0dc3c37cc33f7b61d6

### ft ã®ãƒ¡ãƒªãƒƒãƒˆ

- æœ€å°é™ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§è‰¯ã„ã®ã§ï¼Œã‚³ã‚¹ãƒˆãŒä½ã„
- ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼

- PT ã¯ 10 åˆ†ç¨‹åº¦ã§åˆ©ç”¨å¯èƒ½ã«ãªã£ãŸã€‚
- 2epoch ã ã‘ã ã©å…¨ãå­¦ç¿’ã§ãã¦ãªã„æ¨¡æ§˜
  - 10epoch, early stopping ã§è©¦ã—ã¦ã¿ãŸ
  - ã“ã‚Œã§é§„ç›®ãªã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸è¶³ã‹ã‚‚ã€‚
  - ã‚‚ã†å°‘ã—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¢—ã‚„ã—ã¦ã¿ã‚‹ã‹ã€è‹±èªã§èã„ã¦æ¯”è¼ƒã—ã¦ã¿ã‚‹ã‹ã€‚
  - ã‚µãƒã‚‹ã¾ã§ epoch å›ã™ã‹ï¼Ÿ
